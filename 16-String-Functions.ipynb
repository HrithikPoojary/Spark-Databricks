{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647d15a8-f399-445b-8706-9f0d372bef57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data = [('25' , '07' , '1982')] , schema = ['day' , 'month' , 'year'])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46e989b-3253-4475-9a73-2a52b63892cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat\n",
    "df.selectExpr( \" to_date( day || '-'||  month || '-' ||  year , 'dd-MM-yyyy' ) as date \" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5f10e9-92f3-4afd-9a8f-e2af9a830ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws ,to_date\n",
    "\n",
    "col_expr = to_date (concat_ws('-' , col('year') , col('month') , col('day')) , 'yyyy-MM-dd')\n",
    "\n",
    "print(f\"Type -  {col_expr} \")\n",
    "\n",
    "df.select(col_expr.alias(\"date\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58e69d65-f110-43a6-a085-b100c0cddf4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data = [('sanjay' , 'kalra' , 25 , 'July' , 1982 , 19408.98 )] ,\n",
    "                            schema = ['first_name' , 'last_name' , 'day' , 'month' ,'year' , 'salary'])\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df379107-3674-42f3-868d-1d4f6b7fd0ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number , format_string\n",
    "salary_fmt = format_number('salary' , '$###,###.##').alias(\"salary\")\n",
    "text_fmt = format_string(\"Mr. %s %s was born on %d %s of %d.\",\n",
    "                         \"first_name\" , \"last_name\" , \"day\" , \"month\" , 'year').alias(\"Emp Descrip\")\n",
    "\n",
    "df.select(text_fmt,salary_fmt).show(truncate=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "16-String-Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
