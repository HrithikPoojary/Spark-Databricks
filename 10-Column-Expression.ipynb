{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ff67dbf-175f-40b2-855e-61010e415968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from dev.spark_db.flight_time\").limit(3).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24442db2-622b-430d-9f11-f99b1ebf07dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flight_df = spark.read.table(\"dev.spark_db.flight_time\")\n",
    "\n",
    "flight_df_1 = flight_df.selectExpr(\n",
    "        \"fl_date as dep_date\",\n",
    "        \" to_date (dep_date + dep_time + wheels_on + taxi_in) as arr_date \",\n",
    "        \"dep_date + crs_dep_time as crs_dep_time\",\n",
    "        \"dep_date + dep_time as dep_time\",\n",
    "        \"arr_date + crs_arr_time as crs_arr_time \",\n",
    "        \"arr_date +  arr_time as arr_time\"\n",
    " )\n",
    "#  in select every column is a new column so i can use previous column alias\n",
    "flight_df_1.where(\"op_carrier_fl_num = 1451 and dep_date = '2000-01-01'\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c072081-654d-4d6e-9c1c-44a0297c087b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "flight_df_2 = flight_df.withColumnRenamed('fl_date' , 'dep_date')\\\n",
    "                .withColumn(\"arr_date\"  ,    expr(\" to_date (dep_date + dep_time + wheels_on + taxi_in) \"))\\\n",
    "                .withColumns(\n",
    "                    {\n",
    "                    \"crs_dep_time\" :  expr( \"dep_date + crs_dep_time\"),\n",
    "                    \"dep_time\" :  expr( \"dep_date + dep_time\"),\n",
    "                    \"crs_arr_time\" :  expr(  \"arr_date + crs_arr_time\" ),\n",
    "                    \"arr_time\" : expr(\"arr_date +  arr_time \")\n",
    "                    }\n",
    "                )\n",
    "flight_df_2.where(\"op_carrier_fl_num = 1451 and dep_date = '2000-01-01'\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa34a01-54f3-44e2-97b9-2fd7e24d0efb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col , to_date\n",
    "\n",
    "flight_df_2 = flight_df.withColumnRenamed('fl_date' , 'dep_date')\\\n",
    "                .withColumn(\"arr_date\"  ,     to_date (col(\"dep_date\") + col(\"dep_time\") + col(\"wheels_on\") + col(\"taxi_in\")) )\\\n",
    "                .withColumns(\n",
    "                    {\n",
    "                    \"crs_dep_time\" :  col(\"dep_date\") + col(\"crs_dep_time\"),\n",
    "                    \"dep_time\" :  col(\"dep_date\") + col(\"dep_time\"),\n",
    "                    \"crs_arr_time\" :  col(\"arr_date\") + col(\"crs_arr_time\" ),\n",
    "                    \"arr_time\" : col(\"arr_date\") +  col(\"arr_time\")\n",
    "                    }\n",
    "                )\n",
    "flight_df_2.where((col(\"op_carrier_fl_num\") == 1451) & (col(\"dep_date\") == '2000-01-01')).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10-Column-Expression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
